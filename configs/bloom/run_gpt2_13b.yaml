base_config: [
    './task_config/context.yaml',
    './task_config/runner.yaml',
    './task_config/gpt2_dataset.yaml',
    './model_config/gpt2_13b.yaml',
    '../__base__.yaml' ]

runner_config:
  epochs: 3  # 训练轮数
  batch_size: 8  # per device batch size
  sink_mode: True  # 是否开启数据下沉
  per_epoch_size: 2  # 下沉数据量（0时默认下沉整个数据集）
  initial_epoch: 0  # 恢复训练时设定的已经训练的epoch数
  has_trained_epoches: 0  # 恢复训练时设定已经训练的epoch数
  has_trained_steps: 0  # 恢复训练时设定已经训练的step数

parallel:
  parallel_mode: 1 # 0-dataset, 1-semi, 2-auto, 3-hybrid
  gradients_mean: False  # 是否在梯度的 AllReduce后执行平均算子，不支持单卡
  loss_repeated_mean: False
  full_batch: True # 是否在非数据并行模式下加载整个batch数据集
  search_mode: "sharding_propagation"  # 设置切分策略传播算法
  enable_parallel_optimizer: True  # 是否开启优化器并行
  strategy_ckpt_save_file: "./ckpt_strategy.ckpt"  # 恢复训练的模型的切片

recompute_config:
  recompute: True  # 指定激活层是否切片保存
  parallel_optimizer_comm_recompute: False  # 指定由优化器切分产生的AllGather算子是否进行重计算
  mp_comm_recompute: True  # 指定由模型并行成分产生的通信算子是否进行重计算
  recompute_slice_activation: False  # 指定激活层是否切片保存

# 4 nodes 32 device num
parallel_config:  # 并行设置
  data_parallel: 4  # 数据并行数
  model_parallel: 2  # 模型/Tensor并行数
  pipeline_stage: 4  # 流水线并行数
  optimizer_shard: True  # 是否开启优化器并行
  micro_batch_num: 24  # 流水线并行时将MiniBatch切分成更细的MicroBatch的数目，流水线并行时生效，该值需≥流水线并行数
  vocab_emb_dp: True  # 是否配置embedding为数据并行
  gradient_aggregation_group: 4  # 优化器并行对应的梯度聚合数目

# runner_wrapper:
#   type: MFPipelineWithLossScaleCell
#   scale_sense:
#     type: DynamicLossScaleUpdateCell
#     loss_scale_value: 1024
#     scale_factor: 2
#     scale_window: 1000
#   use_clip_grad: True

callbacks:  # 定义详见mindformers/core/callback/callback.py
  - type: MFLossMonitor
  - type: CheckpointMointor
    prefix: "gpt2-13b"
    save_checkpoint_steps: 50
    integrated_save: False
    async_save: False
  - type: Local2HDFSMonitor
    hosts: "" # HDFS ip
    user_name: "" # HDFS user name
    local_checkpoint_dir: './output' # 默认本地存储ckpt的目录
    upload_per_step: 50 # 每多少step执行一次上传
    async_upload: False # 是否执行异步上传
  - type: ObsMonitor

auto_tune: False  # 数据性能自动优化
autotune_per_step: 10  # 每多少步优化一次

profile: False
use_parallel: True

micro_batch_interleave_num: 1  # 双副本并行

seed: 0
resume_or_finetune_checkpoint: ""  # 恢复训练和finetune指定模型权重


run_mode: 'train'
trainer:
  type: MaskedLanguageModelingTrainer
  model_name: 'gpt2_13b'

# cfts init config
aicc_config:
  obs_path: "s3://wuhang-bucket/zyw/log/log_b8_4_2_4_24_new_new"
  upload_frequence: 6
  keep_last: False